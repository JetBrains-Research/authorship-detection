\section{Данные}\label{sec:data}
Чтобы обучить модель машинного обучения и протестировать её качество, нужен датасет. У имеющихся датасетов есть слабые стороны, которые указывались в работах других исследователей. В этой главе предлагается новый подход к сбору данных для оценки качества решений задачи определения авторства, описывается реализованный инструмент для создания датасетов, использующий этот подход и датасеты, собранные с его помощью.

\subsection{Ограничения существующих датасетов}
Прошлые исследования в области определения авторства исходного кода работали с наборами данных нескольких видов: домашние задания студентов \cite{Frantzeskou2007,Elenbogen2008,Krsul1997}, примеры кода в книгах по программированию \cite{Oman1989,Frantzeskou2006}, решения задач соревнований по программированию \cite{Rosenblum2011,Caliskan2015,Alsulami2017,Simko2018}, проекты с открытым исходным кодом, имеющие одного автора \cite{Shevertalov2009,Kothari2007,Yang2017,Zhang2017}. Первые три типа данных значительно отличаются от промышленного кода: студенты имеют меньше опыта, чем профессиональные разработчики, примеры в книгах – это короткие и неполные фрагменты, на соревнованиях участникам важно написать программу быстро, не задумываясь о читаемости и качестве написанного. Отличия не позволяют однозначно утверждать, что решение, демонстрирующее хорошую точность на таких датасетах, будет так же хорошо работать для промышленного кода, что важно при его применении для решения вопросов интеллектуальной собственности.

Существующие исследования работают не с произвольными проектами с открытым исходным кодом, а только с имеющими одного автора или такими, где хотя бы 90\% кода принадлежит одному разработчику. В датасетах, состоящих из таких проектов, код разных авторов соответствует разным проектам, а значит может иметь разную тематику и функциональность. Из-за этого нельзя быть уверенными в том, что полученное решение будет хорошо работать, если будет применяться для различения кода разработчиков, работающих в одной области или реализующих схожую функциональность, хотя это важно при поиске авторов вредоносного ПО, поиске плагиата, проверке авторства.

Также, у всех четырёх типов данных есть ограничение на количество фрагментов кода, доступных для каждого автора: ограниченный набор задач на соревнованиях и в домашних работах, требуемое количество поясняющих примеров в книгах. Проекты с одним автором также редко состоят из более чем нескольких сотен файлов, поскольку при дальнейшем росте проекта у него появляются пользователи, которые начинают самостоятельно предлагать изменения и вносить свой вклад в его развитие. В то же время, профессиональные программисты пишут гораздо большие объемы кода. Например, в проекте IntelliJ IDEA есть 40 разработчиков, каждый из которых добавил не менее 10000 методов.

\subsection{Методика сбора данных}
В этой работе предлагается метод сбора данных из проектов с произвольным числом разработчиков, разрабатываемых с использованием системы контроля версий (VCS, version control system). Необходимость в VCS не является сильным ограничением, поскольку в настоящее время это общепринятая практика. Самой популярной платформой для загрузки программ с открытым кодом является GitHub\footnote{\url{https://github.com/}}, поддерживающая VCS git. По состоянию на конец 2018 года, платформой пользуется более 30 миллионов разработчиков, создавших 96 миллионов репозиториев \cite{GithubStats}. Датасеты, состоящие из проектов на GitHub, уже использовались в работах по определению авторства \cite{Wisse2015,Yang2017,Alsulami2017,Zhang2017}.

В проектах, использующих VCS, изменения добавляются группами, которые называются коммитами. Коммит чаще всего принадлежит одному автору и состоит из набора изменений, которые могут затрагивать произвольное число файлов. В таблице \ref{tab:repositories} приведены 10 репозиториев на GitHub с самым большим числом коммитов. Каждый коммит можно разбить на изменения, затрагивающие части кода определенного уровня: изменения методов, классов, файлов. Из таких изменений в свою очередь можно составить датасет, поскольку для каждого из них автор известен благодаря VCS. В этой работе рассматриваются изменения отдельных методов.

\vskip 1em
	\begin{table}[ht]
		\caption{Репозитории на GitHub с самым большим числом коммитов}
		\centering
    	\begin{tabular}{| l | l | l |}
    		\hline
    		\textbf{Репозиторий}  & \textbf{Число коммитов (тыс.)} & \textbf{Основной язык} \\ \hline
    		torvalds/linux & 782 & C \\ \hline
    		LibreOffice/core & 428 & C++ \\ \hline
    		liferay/liferay-portal & 283 & Java \\ \hline
    		jsonn/pkgsrc & 266 & Makefile \\ \hline
    		freebsd/freebsd & 254 & C \\ \hline
    		JetBrains/intellij-community & 230 & Java \\ \hline
    		cms-sw/cmssw & 194 & C++ \\ \hline
    		openbsd/src & 192 & C \\ \hline
    		NixOS/nixpkgs & 154 & Nix \\ \hline
    		Wikia/app & 152 & PHP \\ \hline
    	\end{tabular}
		\label{tab:repositories}
	\end{table}

Использование такого подхода затруднено тем, что git, являющийся самой популярной VCS, не хранит подробную информацию об изменениях. Это означает, что чтобы получить информацию об изменении метода, нужно найти его в старой и новой версии файла, что может быть проблематичным в случае переименования или изменения сигнатуры. Для решения этой проблемы была использована библиотека GumTree \cite{GumTree}, позволяющая строить AST по коду на языке Java и искать по версиям файла до и после коммита изменившиеся методы и соответствующие им поддеревья в обеих версиях.

Для сбора данных была написана библиотека на двух языках, Python и Kotlin. Часть, написанная на Python, обрабатывает историю проекта, отслеживая в ней изменения отдельных файлов с кодом на Java, и сохраняет информацию о них в бинарном виде. Часть, написанная на Kotlin, проходит по истории изменения Java-файлов и для каждого файла строит AST и определяет изменившиеся методы при помощи библиотеки GumTree \cite{GumTree}. Информация об AST изменившихся методов сохраняется, образуя данные для построения датасетов.

\subsection{Собранные датасеты}
С помощью инструмента из истории проекта IntelliJ IDEA были извлечены все изменения отдельных методов. Это 2 миллиона изменений, принадлежащих 500 разработчикам. Из них 98\% сделаны 100 самыми активными разработчиками, а 90\% — 50 самыми активными. 700 тысяч изменений являются добавлениями метода и не требуют дополнительной адаптации алгоритмов определения авторства, умеющих работать с фрагментами кода.

Из изменений затем было создано 7 датасетов. Во всех датасетах выборка заранее разделена на тренировочную и обучающую в отношении 70\%/30\%, при этом в тренировочной и тестовой выборке изменения методов относятся к разным файлам. Датасеты 1-4 моделируют условия разного количества разработчиков, количества доступных примеров и разной степени несбалансированности между классами. Степень сбалансированности выражается отношением максимального числа фрагментов кода среди программистов, попавших в датасет, к минимальному. Подробная информация о датасетах 1-4 приведена в таблице \ref{tab:datasets}. 

В датасетах 2-4 требуется предсказать автора не для одного метода, а для группы из нескольких, выбранных случайным образом из примеров, входящих в тренировочную или тестовую выборку. Такая постановка задачи заставляет решение поддерживать возможность работы с несколькими фрагментами кода, что может встречаться при практическом применении к задачам проверки авторства, поиске авторов вредоносных программ и анализе стиля кода.

\vskip 1em
	\begin{table}[ht]
		\caption{Датасеты с разной сбалансированностью и числом разработчиков, построенные по проекту IntelliJ IDEA}
		\centering
    	\begin{tabular}{|c|c|c|c|c|}
            \hline
                                           & \textbf{IDEA1} & \textbf{IDEA2} & \textbf{IDEA3} & \textbf{IDEA4} \\ \hline
            \textbf{Число авторов}         & 10             & 16             & 50             & 20             \\ \hline
            \textbf{Число примеров (тыс.)} & 912            & 648            & 1623           & 1228           \\ \hline
            \textbf{Макс. / Мин. примеров} & 5              & 3              & 32             & 8.5            \\ \hline
            \textbf{Примеров в группе}     & 1              & 16             & 16             & 16             \\ \hline
            \textbf{Деление по пакетам}     & 0              & 0             & 0             & 0             \\ \hline
			\end{tabular}%
		\label{tab:datasets}
	\end{table}

Основным отличием наборов данных получаемых из одного проекта по сравнению с наборами, состоящими из проектов написанных разными авторами, является меньшая разница в тематике и функциональности кода разных разработчиков, которую мы называем рабочим контекстом. Хотя внутри одного проекта также существует разделение по областям ответственности между разработчиками, оно менее значительно. Чтобы сократить его ещё больше, были созданы датасеты 4, 5 и 6, в которых тренировочная и тестовая выборки разделены по пакетам разного уровня. Нулевой уровень соответствует тому, что методы в тренировочной и обучающей выборке относятся к разным файлам, это верно для всех собранных датасетов. Первый уровень запрещает примерам в выборках находится в одной директории, а второй уровень — лежать в одной над-директории, при этом проверка осуществляется по файлу, над-директория которого лежит менее глубоко. Таким образом, тренировочный и тестовый код каждого разработчика относятся к разным частям проекта, что позволяет определить, влияет ли рабочий контекст на результаты тестирования.

В датасете 7 тренировочная и тестовая выборки разбиты по времени. Эксперименты с разделением данных по времени ставились в работе Калискан и др. \cite{Caliskan2015}. В их работе рассматривались 25 программистов, участвовавших в GCJ в 2012 и 2014 годах. Их решения 2012 года были тренировочной выборкой, а решения 2014 — тестовой. В обе выборки входило по 9 решений для каждого человека, ограничение вызвано количеством задач в соревновании. Метод, предложенный в этой работе, позволяет проводить исследования изменения стиля кода со временем в гораздо большем масштабе: для попавших в датасет программистов доступны десятки тысяч примеров. Более подробная информация о датасетах 5-7 приведена в таблице \ref{tab:datasets-cool}.


\vskip 1em
	\begin{table}[ht]
		\caption{Датасеты с разделением по времени и по пакетам разного уровня, построенные по проекту IntelliJ IDEA}
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
										& \textbf{IDEA5} & \textbf{IDEA6} & \textbf{IDEA7} \\ \hline
			\textbf{Число авторов}         & 20   & 20   & 10  \\ \hline
			\textbf{Число примеров (тыс.)} & 1228 & 1228 & 912 \\ \hline
			\textbf{Макс. / Мин. примеров} & 8.5  & 8.5  & 5   \\ \hline
			\textbf{Примеров в группе}     & 16   & 16   & 16  \\ \hline
			\textbf{Деление по пакетам}    & 1    & 2    & 0   \\ \hline
			\textbf{Деление по времени}    & -    & -    & +   \\ \hline
			\end{tabular}%
		\label{tab:datasets-cool}
	\end{table}

\subsection{Выводы}
В этой работе предлагается метод сбора данных для тестирования решений задачи определения авторства кода из проектов с произвольным числом авторов. Он позволяет составлять датасеты для тестирования моделей в различных условиях: при разделении выборки по времени, по рабочему контексту, для разного количества примеров, доступных для каждого разработчика. Предложенный метод реализован для работы с языком Java и протестирован на втором по величине Java-проекте на GitHub, IntelliJ IDEA. В результате получен набор из 7 датасетов, позволяющих проверку моделей для определения авторства в разных условиях.
