\section{Обзор литературы}\label{sec:literature}

\subsection{История развития области}

Первоначально задача установления авторства появилась в литературе не позднее, чем в XIX веке. Первые исследования, связанные с авторством программного кода, появились только в 1970-е \cite{Ottenstein1976} и основывались на теории программного обеспечения, разработанной Холстедом \cite{Halstead1972,Halstead1975}. Теория утверждала, что всего четырёх метрик и их комбинаций достаточно, чтобы передать внутренние свойства программы, в том числе, различия в коде, написанном разными авторами. Метрики, названные метриками Холстеда, приведены в таблице \ref{tab:halstead}.

В дальнейшем было показано, что предсказания теории расходятся с эмпирическими данными \cite{Hamer1982,Shen1983}, но, несмотря на это, она дала начало исследованиям по поиску сходств в программах. Первоначально они были направлены на автоматическое определение списывания в домашних заданиях.

В дальнейшем теорию активно развивали: был предложен алгоритм для быстрого вычисления метрик по коду \cite{Bulut1974}, показана связь между размером проекта, временем, потраченным на его разработку и метриками Холстеда \cite{Albrecht1983}. Фитцсиммонс \cite{Fitzsimmons1978} продемонстрировала, что при достаточно большом количестве программ теория программного обеспечения даёт точные оценки на число ошибок, допущенных в коде. Несмотря на поддержку теории частью учёных, подвергались критике её расхождения с эмпирическими данными \cite{Hamer1982, Shen1983}.

\vskip 1em
	\begin{table}[ht]
        \caption{Метрики Холстеда \cite{Halstead1972}.}
		\centering
        \begin{tabular}{|c|c|}
            \hline
            \textbf{Метрика} & \textbf{Определение} \\ \hline
            n1 & Число различных операторов \\ \hline
            n2 & Число различных операндов \\ \hline
            N1 & Суммарное число операторов \\ \hline
            N1 & Суммарное число операндов \\ \hline
            \end{tabular}
		\label{tab:halstead}
   \end{table}

Задача определения авторства исходного кода впервые привлекла внимание исследователей в 1989 году. Оман и Кук \cite{Oman1989} показали, что авторов программ можно различить с хорошей точностью, основываясь на статистическом анализе метрик форматирования. К ним относится расстановка переносов строк, отступов, длины названий переменных и функций, типы комментариев. Авторы не учитывали, что часть из этих метрик легко изменить при помощи текстовых редакторов или сред разработки.

Затем, Спэффорд и др. \cite{Spafford1993} впервые заговорили о применении автоматического определения авторства кода для решения вопросов интеллектуальной собственности. Авторы утверждали, что у каждого программиста есть свой уникальный стиль, по которому его можно определить, точно так же, как это делается по почерку в судебно-медицинской экспертизе. Несмотря на отсутствие эмпирической проверки этих утверждений, в работе было приведено большое количество метрик или факторов, по которым можно определять стиль программиста: использование библиотек, возможностей языка, допускаемые ошибки, стиль форматирования и комментариев, названия переменных и ошибки в них. В дальнейшем они использовались во многих работах по установлению авторства \cite{Macdonell1999,Ding2004,Lange2007,Kothari2007,Caliskan2015,Yang2017}.

Определение авторства в литературе и программировании являются похожими по формулировке задачами, но между областями есть существенные различия. В работе \cite{Krsul1997} авторы пришли к выводу, что определить автора фрагмента кода сложнее, чем литературного текста. Это вызвано тем, что разработчики переиспользуют код, работают в командах, используют среды разработки, автоматически форматирующие код, используют сторонние библиотеки и инструменты. В работе \cite{Sallis1996} было показано, что несмотря на вышеописанные различия, методы из области обработки естественного языка (ОЕЯ или NLP, Natural Language Processing) могут давать хорошие результаты, если будут использованы вместе с метриками программного обеспечения.

Последующие работы \cite{Krsul1997, Gray1998, Macdonell1999} сфокусировались на расширении множества используемых факторов, в том числе добавляя факторы, применимые для конкретного языка программирования, например, число директив препроцессора в C++ \cite{Macdonell1999}. В 2004 году Динг и др. \cite{Ding2004} применили отбор факторов для определения авторства кода на Java. Они использовали набор метрик из предыдущих работ и отфильтровали его при помощи пошагового дискриминантного анализа и дисперсионного анализа. Оба способа показали улучшение точности с 62\% до 85\% по сравнению с использованием всех метрик.

В то время как вышеописанные исследования работали с метриками, которые понятны человеку и на основе которых люди могут считать код похожим, в работе Франческу и др. \cite{Frantzeskou2006, Frantzeskou2007} были использованы N-граммы, полученные по коду. N-граммы — это последовательности из N идущих подряд символов, например, 4-граммы строки “СТРОКА” это {“СТРО”, “ТРОК”, “РОКА”}. Авторы построили профиль для каждого автора, состоящий из нескольких тысяч наиболее часто встречающихся N-грамм в его документах. Определение автора нового документа состояло из построения по нему набора N-грамм такого же размера и нахождения самого близкого профиля по размеру пересечения с набором. Такой подход показал высокую точность при различении как студенческих заданий на Java, так и проектов с открытым исходным кодом, при этом будучи простым с точки зрения вычислений и независимым от языка программирования.

Из-за простоты и эффективности анализа N-грамм он использовался во многих последующих работах \cite{Burrows2007, Krishna2006, Layton2010}. Бёрроуз и др. \cite{Burrows2007} исследовали применение N-грамм к изменённой версии кода, в которой оставлены только операторы и ключевые слова. Кришна и др. \cite{Krishna2006} использовали подход для поиска компьютерных вирусов. Лейтон и др. \cite{Layton2010} определяли с его помощью авторов фишинговых программ.

Общей проблемой анализа N-грамм для определения авторства является выбор N. В разных работах, в зависимости от данных и метрики оценки, оптимальные значения варьируются от 4 \cite{Kothari2007} до 20 \cite{Burrows2007}. Второй проблемой оказалось падение точности при увеличении числа различаемых программистов \cite{Burrows2007}. Последующие работы переключились с анализа синтаксического сходства кода на анализ его семантики \cite{Vinod2012, Caliskan2015, Chen2010}.


К 2007 году сформировался общий подход к решению задачи определения авторства, подробно описанный в работе Котари \cite{Kothari2007}. Он имеет следующую структуру: сперва собирается набор фрагментов кода, для которых известны авторы. Фрагментами могут быть как целые файлы, так и отдельные классы или методы. Собранный набор данных разделяется на обучающую или тренировочную и тестовую выборки. По каждому фрагменту в обучающей выборке считается заданный набор метрик (например, частоты N-грамм \cite{Frantzeskou2006} или метрики, специфичные для языка \cite{Macdonell1999}), называемый численным представлением фрагмента. Затем выбирается модель для решения задачи и обучается на тренировочных представлениях. Она может агрегировать информацию для отдельных авторов в профили или же пользоваться ей в явном виде. Качество обученной модели проверяется на тестовой выборке.

\subsection{Выбор данных}

Получаемые результаты зависят от того, какие данные были собраны. Чтобы можно было утверждать о применимости модели на практике, она должна быть протестирована на данных, близких к реальным. В исследованиях 90-х годов \cite{Krsul1997, Leach1995} в качестве датасетов использовались домашние задания студентов. Это вызывало проблемы с распространением данных, поскольку их требовалось анонимизировать, удалять комментарии.

Помимо домашних заданий в работах использовались примеры кода из книг по программированию и код, представленный в качестве примера авторами компиляторов \cite{Macdonell1999, Oman1989}. В случае таких фрагментов считалось, что весь код в одной книге или одном компиляторе написан одним человеком, что не обязательно является правдой.

С ростом популярности программ с открытым исходным кодом и сервисов для их загрузки исследователи стали использовать их в качестве датасетов. Так, использовались фрагменты кода, скачанные на freshmeat\footnote{\url{http://freshmeat.sourceforge.net/}} \cite{Frantzeskou2006}, SourceForge\footnote{\url{http://sourceforge.net/}} \cite{Lange2007, Shevertalov2009}, planet-source-code\footnote{\url{https://www.planet-source-code.com/}} \cite{Bandara2013}. Такие данные ближе к промышленному коду, чем домашние задания или код из книг, но при этом фрагменты разных авторов могут относиться к проектам разной тематики. Это вызывает у исследователей опасение, что итоговое решение учится различать тематику проекта, а не его автора \cite{Caliskan2015}.

Розенблум и др. \cite{Rosenblum2011} стали первыми, кто в качестве датасета использовались решения участников Google Code Jam (GCJ). GCJ — ежегодное соревнование по программированию, проводимое компанией Google с 2008 года. Соревнование состоит из нескольких раундов, в каждом из которых участникам предлагается набор из нескольких алгоритмических задач, которые требуется решить за ограниченное время. Хотя решения принимается на большинстве популярных языков программирования, чаще всего используются C++, C и Python. Все корректные решения, отправленные во время соревнования, доступны для скачивания и активно используются исследователями, занимающимися задачей определения авторства \cite{Rosenblum2011, Caliskan2015, Alsulami2017, Simko2018}. Это вызвано тем, что все участники решают одни и те же задачи, а значит их код должен выполнять одну функцию, различаясь только индивидуальными особенностями авторов. Тем не менее, использование данных GCJ подвергается критике \cite{Dauber2017} за свою искусственность: код в решениях алгоритмических задач может сильно отличаться от промышленного кода.

Помимо нового подхода к выбору данных, в работах Розенблума и др. \cite{Rosenblum2010,Rosenblum2011,Rosenblum2011-2} был предложен новый способ определения автора по бинарным файлам и возможность восстановить набор инструментов, которым бинарный файл был получен: компилятор, его версию и уровень оптимизации. В этой серии работ была предложена методика получению факторов по бинарному коду. Для этого сперва из бинарного файла извлекается код отдельных функций или логических блоков и граф потока управления. Затем в коде ищутся идиомы — последовательности из 1-3 инструкций, содержащие низкоуровневую информацию о логике кода — наличие которых является фактором. В графе потока управления ищутся графлеты — подграфы из 3 вершин, которые отражают локальную структуру программы.  Количества найденных графлетов каждого типа является фактором. В итоге авторы получили точность 51\% при определении автора бинарного файла, выбирая из 191 автора.

\subsection{Выбор методов}

Помимо развития в выборе данных и метрик происходило развитие в выборе методов. Для определения авторства исходного кода применялись разные методы машинного обучения.

Часть работ использовали подходы, основывающиеся на поиске похожих фрагментов: метод ближайших соседей \cite{Keselj2003, Lange2007, Frantzeskou2006}, ранжирование \cite{Burrows2007, Shevertalov2009}. Суть этих подходов заключается в подсчёте расстояния между численными представлениями кода. Автором фрагмента кода считается автор большинства близких к нему фрагментов обучающей выборке. Расстоянием может выступать расстояние в векторном пространстве \cite{Shevertalov2009}, пересечение гистограмм \cite{Lange2007} или специально подобранная метрика, например, пересечение наборов N-грамм \cite{Frantzeskou2006,Frantzeskou2007}. В работе Бёрроуза и др. \cite{Burrows2007}, исследовавшей определение авторства на основе ранжирования, сравнивалась эффективность четырёх расстояний: косинусной меры, языковой модели со сглаживанием Дирихле, BM25 и предложенной авторами метрики. Лучшие результаты показало использование BM25, что согласуется с результатами в области информационного поиска \cite{Robertson2009}.

Также исследователи применяли вероятностные методы: байесовский классификатор \cite{Kothari2007} и логистическую регрессию \cite{Bandara2013}. Суть этих методов заключается в оценке вероятности того, что фрагмент кода принадлежит автору, при условии того, что в нём встречаются определённые N-граммы символов или токенов. Несмотря на хорошие результаты обеих работ относительно других исследований своего времени, в случае вероятностных подходов сложнее расширять множество факторов, поэтому их используют реже в пользу других методов.

В недавних работах популярностью пользуются методы, работающие с набором факторов как с векторами. К таким методам относится дискриминантный анализ \cite{Ding2004, Hayes2008, Hayes2010} и метод опорных векторов \cite{Rosenblum2011, Wisse2015, Meng2016}. Сперва по фрагментам кода подсчитывается набор из $n$ метрик, образуя $n$-мерный вектор численного представления фрагмента. Примеры кода разных авторов образуют множества из векторов в $n$-мерном пространстве, и, если подобран качественный набор метрик, множества можно различить. Дальнейшую задачу дискриминантный анализ и метод опорных векторов решают по-разному. 

Дискриминантный анализ трактует векторы фрагментов кода как примеры, полученные из разных случайных распределений. Задача определения авторства в таком случае сводится к подбору параметров распределений, которые наилучшим образом объясняют примеры из обучающей выборки, а для примеров из тестовой выборки в качестве предсказания берется автор, к распределению которого вектор кода относится с наибольшей вероятностью.

Метод опорных векторов основан на поиске поверхности, которая наилучшим образом отделяет в пространстве векторы одного класса от всех остальных. В самом простом случае поверхностью является плоскость, в более сложных применяется метод опорных векторов с ядром, что позволяет искать более сложные поверхности. Для применения метода к новым примерам вычисляется их положение относительно разделяющих поверхностей.

Ещё одним методом, использовавшимся для решения задачи определения авторства, является решающее дерево. Оно применялось в работе Эленбогена и др. \cite{Elenbogen2008}. Для построения дерева авторы применяли алгоритм C4.5 \cite{Quinlan1993}. Это жадный алгоритм, который строит дерево от корня к листьям, в каждой вершине выбирая фактор и его значение такое, что оно наилучшим образом разбивает часть выборки, дошедшую до вершины, на две части. Затем, алгоритм рекурсивно применяется в двух новых вершинах. Когда дерево построено, чтобы уменьшить переобучение, в нём обрезается часть веток.

Идею решающего дерева развивает случайный лес. Вместо построения одного решающего дерева, используя все доступные данные и факторы, строится от нескольких до сотен или даже тысяч деревьев. Каждое из них строится по случайной части обучающей выборки, используя случайный поднабор факторов.  При определении ответа каждое полученное дерево принимает решение и решение большинства принимается за ответ.  Случайный лес использовали в нескольких недавних работах по установлению авторства \cite{Caliskan2015} и имитации стиля \cite{Simko2018}.

В исследовании по определению авторства Калискан и др. \cite{Caliskan2015} продолжили работу с данными GCJ. В то время как большинство предыдущих исследований работали с кодом как с обычным текстом, отличающимся только форматированием и наличием специальных слов, они использовали факторы, полученные по абстрактному синтаксическому дереву (AST, Abstract Syntax Tree), соответствующему коду. Такие факторы называют синтаксическими, к ним в данной работе относились частоты встречаемости и средние глубины отдельных вершин разных типов и их пар, соединённых ребром. Использование AST позволяет передать внутреннюю структуру кода, которая в свою очередь отвечает за его функциональность. Помимо синтаксических также в работе применялся большой набор метрик форматирования и лексических, что породило около 100 тысяч факторов. Их количество затем было сокращено до 1000 наиболее полезных, при этом критерием отбора была совместная информация между значением фактора и автором. Описанный набор метрик затем использовался другими исследователями \cite{Yang2017}.

По полученному после подсчёта и фильтрации факторов численному представлению Калискан и др. обучили случайный лес из 300 деревьев. В результате они получили решение, которое хорошо масштабировалось на данных GCJ: 98\% точности при различении кода 250 авторов на C++, 92\% при различении 1600. Стоит отметить, что работ со сравнением такого количества программистов ранее не проводилось и результат остаётся лучшим для данных GCJ  на языке C++. Препятствием к дальнейшему увеличению масштаба стали ограничения датасета: только у 1600 участников было 9 решений по одним и тем же задачам.

С развитием методов, использующих нейронные сети в работе с изображениями \cite{He2016}, обработке естественного языка \cite{Young2018} и распознавании речи \cite{Zhang2018-speech}, сети стали применяться и в определении авторства. Нейронная сеть или нейросеть это математическая модель, построенная по принципу организации нейронов в мозгу человека. Нейросеть состоит из элементов, соединенных направленными связями, по которым данные передаются от входных нейронов к следующим элементам, вплоть до выходных нейронов. Элементы применяют к полученным на вход данным различные математические операции: линейную комбинацию, применение нелинейной функции, свертку, сдвиг и так далее. Набор элементов и связей между ними описывается архитектурой нейросети. В области обработки естественного языка для решения задач активно применяются рекуррентные нейронные сети \cite{Jordan1990} и, в частности, LSTM \cite{Hochreiter1997}.

Идея работы с AST при помощи нейронных сетей была продолжена Алсулами и др. \cite{Alsulami2017}. Вместо дальнейшего расширения набора факторов, они применили модификацию LSTM для работы с деревьями \cite{Tai2015}. Она работает следующим образом: каждому типу вершины в AST и токену сопоставляется вектор, называющийся эмбеддинг, изначально случайный, но изменяющийся в процессе обучения сети. Дерево обходится в глубину, в листьях сеть получает на вход эмбеддинг токена, относящегося к листу, в остальных вершинах — векторы, полученные в детях, и эмбеддинг типа текущей вершины. В результате в корне дерева сеть генерирует вектор, являющийся представлением всего дерева. По нему ещё одним линейным слоем с функцией активации softmax делается предсказание. Сеть обучается при помощи стохастического градиентного спуска и алгоритма обратного распространения ошибки.

Тестирование проводилось для языков Python и C++. Для Python были использованы решения по 10 задачам 70 участников GCJ. Для C++ использовались проекты 10 авторов, размещённые на GitHub. Модель достигла точности 88.8\% при распознавании кода на Python 70 авторов, что является лучшим из известных результатов на данный момент.

В работах по установлению авторства кода использовали не только разные архитектуры сетей, но и методы оптимизации для их обучения. В 2017 году Янг и др. \cite{Yang2017} применили набор факторов из работы Калискан и др. \cite{Caliskan2015}, объединив некоторые из них в более общие, и обучили трёхслойную нейросеть для определения автора по ним. Они сравнили два метода обучения: стохастический градиентный спуск (SGD, stochastic gradient decent) и метод роя частиц (PSO, particle swarm optimisation) \cite{Kennedy1995}. Сравнение производилось на датасете из 40 проектов на Java, каждый из которых был написан одним автором. Результаты при использовании PSO оказались значительно лучше, чем при стохастическом градиентном спуске, который обычно используется при обучении нейросетей: 91\% против 76\%. Результат является наилучшим на данный момент для этого набора данных.

Изменение методов машинного обучения, использовавшихся для решения задачи определения авторства, происходило одновременно с эволюцией методов для решения других задач в области машинного обучения на исходном коде. К ним относится генерация кода, определение тематики, генерация описания по фрагменту кода, определение имени метода.

Недавний прогресс в определении имени метода и генерации описания кода связан с техникой векторного представления кода, предложенной Алоном и др. в 2018 году \cite{Alon2018, Alon2019}. Её можно рассматривать как обобщение использования биграмм типов вершин в AST и токенов, предложенных в работе Калискан и др. \cite{Caliskan2015}. По фрагменту кода строится AST и из него извлекаются тройки из пути между парой листьев и токенов, соответствующим им. Такие тройки называются контекстами. Фрагмент представляется набором контекстов, ему соответствующим. Контексту сопоставляется вектор, состоящий из конкатенации эмбеддингов токенов и пути. Затем векторы контекстов агрегируются при помощи механизма внимания \cite{attention}. Это механизм, позволивший улучшить результаты в задачах обработки естественного языка \cite{Young2018}. Вектором для фрагмента является взвешенная сумма векторов контекстов, где весами являются значения внимания.

\subsection{Выводы}

\begin{itemize}
    \item Для трёх разных языков, Java, C++ и Python, наилучшие результаты показывают разные работы. Решения для Java \cite{Yang2017} и C++ \cite{Caliskan2015} используют факторы, специфичные для конкретного языка, что затрудняет их адаптацию к другим. Решение для Python \cite{Alsulami2017} использует только AST, поэтому является универсальным, при этом показывая очень высокую точность. Это позволяет надеяться на то, что используя AST можно получить универсальное решение, показывающее хорошие результаты сразу для нескольких языков.
    \item В исследованиях не рассматривалась работа с большим количеством данных для каждого автора. Это актуально в задачах проверки авторства, кластеризации и профилировании разработчиков. Ограничением для подобных исследований является отсутствие датасета соответствующего размера.
    \item Датасеты в недавних работах состоят из задач олимпиадного программирования \cite{Rosenblum2011,Caliskan2015,Alsulami2017,Simko2018} или из проектов с одним автором \cite{Zhang2017,Alsulami2017,Wisse2015,Bandara2013,Yang2017}. Решения задач на соревнованиях значительно отличаются от промышленного кода: участникам требуется написать решение максимально быстро, что может быть сделано в ущерб читаемости и архитектуре. Чаще всего решение состоит из одного файла, где большая часть кода находится в одной функции. В дополнение к отличиям от промышленного кода, количество доступных данных значительно отличается от обычных проектов, поскольку программисты гораздо реже участвуют в соревнованиях, чем пишут код на работе. В датасетах из проектов, написанных разными людьми, присутствует разница в предметной области между кодом разных авторов. Решение, которое показывает высокую точность на подобных датасетах, может показывать другие результаты применительно к коду разных авторов в одной предметной области, что важно для поиска авторов вредоносных программ. Проблемы обоих видов датасетов можно решить, если собирать данные из крупных проектов с большим количеством авторов.
\end{itemize}